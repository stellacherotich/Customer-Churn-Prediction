{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b> SYRIATEL CHURN ANALYSIS </b>\n",
    "\n",
    "#### Author : Stella Kitur\n",
    "--- \n",
    "## <b> Project Overview </b>\n",
    "In this project I have utilised machine learning algorithms in order to identify any trends that can help in predicting whether a customer that is using SyriaTel will stop (churn) using the services. This is to help SyriaTel in their decision making process as well as in developing methods that might help to reduce the churn rate further.\n",
    "\n",
    "## <b> Business Understanding </b>\n",
    "### <b> Business Problem </b>\n",
    "- Who is SyriaTel?\n",
    "- Customer retention rate is key in the telecommunication domain \n",
    "- Important to know what features are leading to churn rate increase \n",
    "- What are the potential factors for churn?\n",
    "SyriaTel is a Telecommunication company \n",
    "#### <b>Objectives</b>\n",
    "As the data scientist assigned to this project, what are your objectives?\n",
    "1. Identify if there are certain features that can predict whether a customer will churn or not\n",
    "2. Predict as accurately as possible using a model, whether a customer will churn\n",
    "\n",
    "\n",
    "\n",
    "#### <b> Metrics of Success </b>\n",
    "In this model, the metrics of success are outlined as follows :\n",
    "\n",
    "\n",
    "## <b> Data Understanding </b>\n",
    "In conducting this analysis, the CRISP-DM data science process was used.\n",
    "There were : Outline important notes based on the dataset... etc. etc."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# <b> Import Libraries </b>\n",
    "\n",
    "To start off this analysis, we will import the libraries that will be used in this notebook.\n",
    "\n",
    "As well as including the necessary formatting for the data visualisations used throughout the notebook.\n",
    "\n",
    "For convenience, the libraries have been categorised based on the function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries \n",
    "\n",
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "custom_color = custom_colors = [\"#BE5A83\", \"#F2B6A0\", \"#FEF2F4\"] #This is the color pallette for the notebook\n",
    "\n",
    "\n",
    "#Scikit imports\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import xgboost as xgb\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "# Display the shape of the data\n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "print(df.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b> Data Understanding </b>\n",
    "Under this section, we will gain understanding of the dataset while also identifying if there are any missing/duplicated values before proceeding to conduct EDA (Exploratory Data Analysis) on the data to help us identify any key observations in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 5 rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the information of the dataset\n",
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b> Data Cleaning </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values and duplicated values \n",
    "print(df.isnull().sum())\n",
    "print(f\"There are {df.duplicated().sum()} duplicated values.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will change the datatype of area code from an int to an object\n",
    "\n",
    "df['area code'] = df['area code'].astype(object)\n",
    "df['area code'].dtype # Check if the change has been made\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the values in the state column\n",
    "\n",
    "print(df.state.value_counts())\n",
    "print(f\"There are {df['state'].nunique()} values, this is because SyriaTel is based in the USA and there are {df['state'].nunique()} states\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the phone number column\n",
    "\n",
    "df = df.drop('phone number',axis=1)\n",
    "df.head() #inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that calls the categorical columns in the dataset\n",
    "def print_categorical_columns(df):\n",
    "    categorical_cols = df.select_dtypes(include='object').columns.difference(['phone number'])\n",
    "    for col in categorical_cols:\n",
    "        print(col.upper())\n",
    "        print(df[col].unique())\n",
    "        print('_________________________\\n')\n",
    "\n",
    "# Call the function\n",
    "print_categorical_columns(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b> Label Encoding and One-Hot Encoding </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding the State column\n",
    "# Label Encoding is preferred in this case as there are 51 unique values and will replace it with a unique integer.\n",
    "\n",
    "Label_Encoder = LabelEncoder()\n",
    "df['state'] = Label_Encoder.fit_transform(df['state'])\n",
    "df['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical variables to binary representation\n",
    "df[\"international plan\"] = df[\"international plan\"].map({\"no\": 0, \"yes\": 1})\n",
    "df[\"voice mail plan\"] = df[\"voice mail plan\"].map({\"no\": 0, \"yes\": 1})\n",
    "df['churn'] = df['churn'].map({False: 0, True: 1})\n",
    "\n",
    "df.head(6)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <b> Feature Engineering </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering -- Total Expenditure \n",
    "# This will calculate the total expenditure for each customer\n",
    "\n",
    "\n",
    "df['total expenditure'] = df['total day charge'] \\\n",
    "                        + df['total eve charge'] \\\n",
    "                        + df['total night charge'] \\\n",
    "                        + df['total intl charge']\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b> Exploratory Data Analysis </b>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <b> Summary Statistics </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive Summary Statistics \n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <b> Distribution of Features</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Distribution of Features\n",
    "\n",
    "df.drop(columns='churn').hist(figsize=(18, 15), color=\"#BE5A83\");\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice based on this output that the features have different scalings, and we especially take note that not all of them are <b> normally distributed </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the count of churned and non-churned counts in a bar chart \n",
    "\n",
    "churn_counts = df[\"churn\"].value_counts()\n",
    "\n",
    "# Plot the bar chart\n",
    "sns.countplot(x=\"churn\", data=df, palette=custom_colors)\n",
    "plt.xlabel(\"Churn\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Customer Churn Distribution\")\n",
    "plt.xticks([0,1], [\"Not Churned\", \"Churned\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will be used to find the percentage value in different columns\n",
    "def calculate_percentage(column):\n",
    "    percentages = column.value_counts(normalize=True) * 100\n",
    "    return percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_percentages = calculate_percentage(df[\"churn\"])\n",
    "print(churn_percentages)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take note that majority of the customers 85.5% had not churned (2850), while 14.5 % had churned(483). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of churned and non-churned customers by international plan\n",
    "churn_intl_plan = df.groupby(['churn', 'international plan']).size().unstack()\n",
    "total_churn_itl = churn_intl_plan.sum(axis=1)  # Calculate the total count for each churn category\n",
    "percentage_intl_plan = churn_intl_plan.div(total_churn_itl, axis=0) * 100  # Calculate the percentage\n",
    "percentage_intl_plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display as a bar chart\n",
    "\n",
    "# Plots a stacked bar chart to visualize the relationship\n",
    "churn_intl_plan.plot(kind='bar', stacked=True, figsize=(8, 6), color=custom_colors)\n",
    "\n",
    "plt.xlabel('Churn')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Churn Distribution by International Plan')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title='International Plan')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "- Among customers who did not churn (churn=False), approximately 93.50% have \"no\" international plan, and 6.50% have \"yes\" international plan.\n",
    "- Among customers who churned (churn=True), approximately 71.64% have \"no\" international plan, and 28.36% have \"yes\" international plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of churned and non-churned customers by voicemail plan\n",
    "churn_voicemail = df.groupby(['churn', 'voice mail plan']).size().unstack()\n",
    "total_churn_vm= churn_voicemail.sum(axis=1)  # Calculate the total count for each churn category\n",
    "percentage_vm = churn_voicemail.div(total_churn_vm, axis=0) * 100  # Calculate the percentage\n",
    "percentage_vm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display as a bar chart\n",
    "\n",
    "# Plot a stacked bar chart to visualize the relationship\n",
    "churn_voicemail.plot(kind='bar', stacked=True, figsize=(8, 6), color=custom_colors)\n",
    "\n",
    "plt.xlabel('Churn')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Churn Distribution by Voicemail Plan')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title='Voicemail Plan')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b> Observations: </b>\n",
    "\n",
    "- Churned customers (True): 83.44% did not have a voice mail plan (no), while 16.56% had a voice mail plan (yes).\n",
    "\n",
    "- Non-churned customers (False): 70.46% did not have a voice mail plan (no), and 29.54% had a voice mail plan (yes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_area_code = df.groupby('area code')['churn'].value_counts().unstack() / 100\n",
    "churn_area_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_area_code.plot(kind='bar', stacked=True, figsize=(12, 6), color=custom_colors)\n",
    "plt.xlabel('Area Code', fontsize=12)\n",
    "plt.ylabel('Percentage', fontsize=12)\n",
    "plt.title('Churn by Area Code (Percentage)', fontsize=14)\n",
    "plt.legend(title='Churn', loc='upper right')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "\n",
    "1. In area code <u>408</u>, there are 716 customers who did not churn, while 122 customers churned. The churn rate for this area code is relatively lower compared to the non-churn rate.\n",
    "\n",
    "2. Area code <u>415</u> has a higher number of non-churned customers, with 1419 customers, compared to 236 customers who churned. \n",
    "\n",
    "3. In area code <u>510</u>, there are 715 non-churned customers, while 125 customers churned. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b> Multivariate Analysis</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a Correlation Matrix & then displays it as a heatmap\n",
    "corr_matrix = df.corr()\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display as a heat map\n",
    "#using a heatmap to show correlation\n",
    "fig, ax = plt.subplots(figsize=(16,15))\n",
    "mask = np.triu(np.ones_like(df.corr(), dtype=bool))\n",
    "sns.heatmap(df.corr(), linewidths=0.5, mask=mask, square=True, ax=ax, annot=True, cmap=\"RdPu\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_multicollinearity(df, threshold=0.95):\n",
    "    corr_matrix = df.select_dtypes(include=np.number).corr().abs()\n",
    "    correlated_pairs = set()\n",
    "    for col in corr_matrix:\n",
    "        correlated_cols = corr_matrix.index[corr_matrix[col] > threshold]\n",
    "        correlated_pairs.update([(min(col, correlated_col), max(col, correlated_col)) for correlated_col in correlated_cols if col != correlated_col])\n",
    "    for pair in correlated_pairs:\n",
    "        print(f\"{pair[0]} --- {pair[1]}\")\n",
    "    return set(df.columns) & set(col for pair in correlated_pairs for col in pair)\n",
    "\n",
    "# Call the function to check multicollinearity\n",
    "multicollinear_features = check_multicollinearity(df)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <b> <u> Observations: </u></b>\n",
    "\n",
    "The following pairs of features exhibit high correlation above the threshold of 0.95:\n",
    "\n",
    "<ul>\n",
    "<li> <code>total day minutes</code> and <code>total day charge</code></li>\n",
    "<li> <code>total eve minutes</code> and <code>total eve charge</code></li>\n",
    "<li> <code>total night minutes</code> and <code>total night charge</code></li>\n",
    "<li> <code>total intl minutes</code> and <code>total intl charge</code></li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "We can therefore take note that: \n",
    "\n",
    "There is a strong positve correlation between : \n",
    "\n",
    "- total day minutes and total day charge. This suggests that as the number of minutes spent on day calls increases, the corresponding charge for those calls also increases.\n",
    "\n",
    "- total eve minutes and total eve charge. This indicates that higher evening call durations are associated with higher charges for those calls.\n",
    "\n",
    "- total intl minutes is highly correlated with total intl charge. This indicates that longer international call durations are associated with higher charges for those calls.\n",
    "\n",
    "\n",
    "In order to deal with the multicollinearity in the features, one of the features from each pair will have to be dropped. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop some columns in order to deal with multicollinearity\n",
    "\n",
    "df = df.drop(columns=['total day minutes', 'total eve minutes', 'total night minutes', 'total intl minutes'])\n",
    "df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b> Data Preparation for ML Purposes \n",
    "\n",
    "#### Setting the target </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df.drop('churn', axis=1)\n",
    "y = df.churn\n",
    "X.head() #Inspect new df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop('area code', axis=1).select_dtypes(include=['int', 'float'])\n",
    "X_test = X_test.drop('area code', axis=1).select_dtypes(include=['int', 'float'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info() # inspect the changes made in the cell above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of SMOTE\n",
    "smote = SMOTE(random_state=123)\n",
    "\n",
    "# Resample the training data using SMOTE\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train) \n",
    "\n",
    "# Print the class distribution of the synthetic samples\n",
    "class_distribution = pd.Series(y_train_resampled).value_counts()\n",
    "print(\"Synthetic Sample Class Distribution:\")\n",
    "print(class_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE not applied to test data\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "y_train_resampled.value_counts().plot(kind='pie', autopct='%.2f', textprops={'fontsize': 20}, colors=custom_colors, ax=ax)\n",
    "ax.set_ylabel('Churn', fontsize=16)\n",
    "ax.set_title('Churn distribution in percentage', fontsize=20);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of the churn classes is now balanced. SMOTE was applied on the training sets only.\n",
    "\n",
    "This ensured that an accurate gauge can be made on the model's performance by using a raw test sample that has not been oversampled or undersampled."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b> Modeling\n",
    "\n",
    "The models that are used in this analysis include: </b>\n",
    "\n",
    "1. Logistic Regression\n",
    "\n",
    "2. Decision Tree\n",
    "\n",
    "3. Random Forest\n",
    "\n",
    "4. K Nearest Neighbors\n",
    "\n",
    "\n",
    "## <b>Logistic Regression Model </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline\n",
    "pipe_log = Pipeline(steps=[('scale', StandardScaler()), ('logreg', LogisticRegression(fit_intercept=False, solver='liblinear'))])\n",
    "pipe_log.fit(X_train_resampled, y_train_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X_test, y_test, cmap='RdPu'):\n",
    "    y_train_preds = model.predict(X_train_resampled)\n",
    "    y_test_preds = model.predict(X_test)\n",
    "    \n",
    "    print('Recall Score:')\n",
    "    print('Train:', recall_score(y_train_resampled, y_train_preds))\n",
    "    print('Test:', recall_score(y_test, y_test_preds))\n",
    "    \n",
    "    print('\\nPrecision Score:')\n",
    "    print('Train:', precision_score(y_train_resampled, y_train_preds))\n",
    "    print('Test:', precision_score(y_test, y_test_preds))\n",
    "    \n",
    "    print('\\nAccuracy Score:')\n",
    "    print('Train:', accuracy_score(y_train_resampled, y_train_preds))\n",
    "    print('Test:', accuracy_score(y_test, y_test_preds))\n",
    "\n",
    "    print('\\nF1 Score:')\n",
    "    print('Train:', f1_score(y_train_resampled, y_train_preds))\n",
    "    print('Test:', f1_score(y_test, y_test_preds))\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_test_preds, labels=model.classes_)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    disp.plot(ax=ax, cmap=cmap)\n",
    "    ax.set_title('Confusion Matrix')\n",
    "    ax.set_xlabel('Predicted Label')\n",
    "    ax.set_ylabel('True Label')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(pipe_log, X_test, y_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b> Observations </b>\n",
    "\n",
    "<b>1. Recall Score: </b>\n",
    "\n",
    "The model achieves a recall of approximately 75% on the training data and 74% on the test data.\n",
    "\n",
    "This means that the model is successful in correctly identifying around 74-75% of the actual positive cases in both sets.\n",
    "\n",
    "The relatively consistent performance suggests that the model generalizes well.\n",
    "\n",
    "<b>2. Precision Score:</b>\n",
    "\n",
    " The precision score indicates the proportion of correctly predicted positive cases out of all predicted positive cases.\n",
    "\n",
    "The model achieves a precision of approximately 70% on the training data, but it drops significantly to around 27% on the test data.\n",
    "\n",
    "This discrepancy suggests that the model may be prone to a large number of false positives when applied to unseen data.\n",
    "\n",
    "<b>\n",
    "3. Accuracy Score:</b>\n",
    "\n",
    "The model attains an accuracy of approximately 72% on the training data and 70% on the test data.\n",
    "\n",
    "While the accuracy is relatively high, it is important to note that accuracy alone may not provide a comprehensive assessment of model performance, especially in imbalanced datasets.\n",
    "\n",
    "Overall, the model's performance seems to indicate some potential issues with generalization, as evidenced by the lower precision and slightly lower accuracy on the test data. It is advisable to further investigate and potentially fine-tune the model to improve its performance on unseen data.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <b> Non Parametric Models </b>\n",
    "---\n",
    "## <b> Decision Tree Model </b>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline\n",
    "pipe_dt = Pipeline(steps=[('scale', StandardScaler()), ('clf', DecisionTreeClassifier(criterion='entropy', random_state=42))])\n",
    "pipe_dt.fit(X_train_resampled, y_train_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(pipe_dt, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importances(pipe, figsize, custom_color):\n",
    "    model = pipe.steps[1][1]\n",
    "    plt.figure(figsize=figsize)\n",
    "    bars = plt.barh(X_train_resampled.columns, model.feature_importances_, align='center')\n",
    "    \n",
    "    # Set custom color for the bars\n",
    "    for bar in bars:\n",
    "        bar.set_color(custom_color)\n",
    "    \n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.show()\n",
    "\n",
    "custom_color = \"#BE5A83\"  # Custom color for the bars to match the theme\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importances(pipe_dt, (10, 8), custom_color)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b> Observations </b>\n",
    "\n",
    "From the above visualisation, we observe the following are the most <u> key features </u> in determining whether a customer will churn or not. \n",
    "\n",
    "- Total Expenditure \n",
    "\n",
    "- Customer Service Calls\n",
    "\n",
    "- Total intl charge\n",
    "\n",
    "- Total night charge \n",
    "\n",
    "- Voicemail plan\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature Selection \n",
    "\n",
    "rfecv = RFECV(estimator=DecisionTreeClassifier(random_state=42), scoring='recall')\n",
    "pipe_dt2 = Pipeline(steps=[('scale', StandardScaler()), ('Feature Selection', rfecv), ('clf', DecisionTreeClassifier(random_state=42))])\n",
    "pipe_dt2.fit(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The optimal number of features are {rfecv.n_features_}' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank these features - with 1\n",
    "\n",
    "rfecv_df = pd.DataFrame(rfecv.ranking_,index=X_train_resampled.columns,columns=['Rank']).sort_values(by='Rank',ascending=True)\n",
    "rfecv_df[rfecv_df['Rank'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We will drop the features that are not optimal in predicting churn rate\n",
    "\n",
    "cols = rfecv_df[rfecv_df['Rank'] == 1].index\n",
    "X_train_resampled = X_train_resampled[cols]\n",
    "X_test = X_test[cols]\n",
    "X_train_resampled.head(3) # Inspects the dataframe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b>HyperParameter Tuning for Decision Tree</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dt = {'clf__criterion': ['gini', 'entropy'],\n",
    "             'clf__max_depth': range(14, 32, 2),\n",
    "             'clf__min_samples_split' : range(2, 10, 2),\n",
    "             'clf__min_samples_leaf': [2, 3, 5, 7, 10],\n",
    "             'clf__max_features': [11, 13, 15]\n",
    "}\n",
    "\n",
    "gridsearch_dt = GridSearchCV(pipe_dt, params_dt, cv=4, scoring='recall')\n",
    "gridsearch_dt.fit(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters that gave the best result\n",
    "print(f'The optimal parameters in this model are: {gridsearch_dt.best_params_}')\n",
    "print()\n",
    "# Mean cross-validated score of the best_estimator\n",
    "print(f'The validation recall: {gridsearch_dt.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "evaluate(gridsearch_dt, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importances(pipe_dt, (10, 8), custom_color)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b> Random Forest Model </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create a pipeline for Random Forest Model\n",
    "pipe_rf = Pipeline(steps=[('scale', StandardScaler()), ('rf', RandomForestClassifier(random_state=42))])\n",
    "pipe_rf.fit(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model performance\n",
    "evaluate(pipe_rf, X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b> Hyperparameter tuning on the Random Forest Model </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter tuning using GridSearchCV for Random Forest\n",
    "params_rf = {'rf__n_estimators': range(400, 800, 200),\n",
    "             'rf__criterion': ['gini', 'entropy'],\n",
    "             'rf__max_depth': range(14, 20, 2),\n",
    "             'rf__min_samples_split': range(3, 4, 7),\n",
    "             'rf__min_samples_leaf': [5, 7, 12]\n",
    "             \n",
    "}\n",
    "\n",
    "gridsearch_rf = GridSearchCV(pipe_rf, params_rf, cv=4, scoring='recall')\n",
    "gridsearch_rf.fit(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters that gave the best result\n",
    "print(f'The optimal parameters in this model are: {gridsearch_rf.best_params_}')\n",
    "print()\n",
    "# Mean cross-validated score of the best_estimator\n",
    "print(f'The validation recall: {gridsearch_rf.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the performance of the model\n",
    "evaluate(gridsearch_rf, X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b> Support Vector Machine </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline for SVM\n",
    "pipe_svm = Pipeline(steps=[('scale', StandardScaler()), ('svm', SVC(random_state=42))])\n",
    "\n",
    "# Fit the pipeline on the resampled training data\n",
    "pipe_svm.fit(X_train_resampled, y_train_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(pipe_svm, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_svm = {\n",
    "    'svm__C': [0.1, 1, 10],\n",
    "    'svm__kernel': ['linear', 'rbf'],\n",
    "    'svm__gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "gridsearch_svm = GridSearchCV(pipe_svm, params_svm, cv=4, scoring='recall')\n",
    "gridsearch_svm.fit(X_train_resampled, y_train_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = gridsearch_svm.best_params_\n",
    "best_score = gridsearch_svm.best_score_\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(gridsearch_svm, X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# <b> Model Evaluation </b>\n",
    "\n",
    "\n",
    "Based on the <u> Recall Scores </u> which was the main evaluation metrics in this classification model,\n",
    "the best model to predict whether a customer would churn or not\n",
    "is the <b><u>Decision Tree Model. </u></b>\n",
    "\n",
    "This is due to the fact that it showed the best performance compared to all the other models that were utilised in this model.\n",
    "\n",
    "<ul> <li> The recall score for the model was : 86.4 % </ul> </li>\n",
    "\n",
    "<ul> <li> The optimal parameters in this model are: {'clf__criterion': 'entropy', 'clf__max_depth': 24, 'clf__max_features': 15, 'clf__min_samples_leaf': 2, 'clf__min_samples_split': 2} </ul> </li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation metrics of the best model based on the test data\n",
    "print('DECISION TREE(TUNED) SCORES:')\n",
    "print('Test Recall score: ', recall_score(y_test, gridsearch_dt.predict(X_test)))\n",
    "print('Test Precision score: ', precision_score(y_test, gridsearch_dt.predict(X_test)))\n",
    "print('Test Accuracy score: ', accuracy_score(y_test, gridsearch_dt.predict(X_test)))\n",
    "print('F1 Score: ' , f1_score(y_test, gridsearch_dt.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importances(gridsearch_dt.best_estimator_, (10, 8), custom_color)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# <b> Conclusion & Recommendations </b>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the model results, as the Data Scientist assigned to this project, I would recommend the following.\n",
    "\n",
    "1. As <b> total expenditure </b> is an influencing factor for whether or not a customer will churn; \n",
    "\n",
    "    It is important that SyriaTel reconsiders some of the costs, perhaps in a way that would be more accomodating to individuals that \n",
    "have a certain budget. \n",
    "\n",
    "2. Additionally, focus should be placed on the issues that are raised during the <b> customer service calls </b>, while also ensuring that those who are responding to the customers needs are adequately trained as well as adhering to good customer service norms, in order to ensure quality service is provided. \n",
    "\n",
    "3. Furthermore, SyriaTel should consider taking a customer-centered approach, for example having certain plans that can be modified to suit the needs of the diverse customer base, example: some customers may be more interested in the international plan compared to having a voice mail plan."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
